{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,  f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/train_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "test_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/test_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "\n",
    "labels_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/tcga_sample_identifiers.tsv', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train_tcga_df['sample_id']\n",
    "test_id = test_tcga_df['sample_id']\n",
    "label_id = labels_tcga_df['sample_id']\n",
    "\n",
    "merge_train = []\n",
    "merge_test = []\n",
    "\n",
    "for i in train_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_train.append(str(val['cancer_type']).split()[1])\n",
    "    \n",
    "for i in test_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_test.append(str(val['cancer_type']).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "      <th>10002</th>\n",
       "      <th>10003</th>\n",
       "      <th>100037417</th>\n",
       "      <th>...</th>\n",
       "      <th>9988</th>\n",
       "      <th>9989</th>\n",
       "      <th>999</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9997</th>\n",
       "      <th>cancer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-LL-A73Z-01</td>\n",
       "      <td>202.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>329.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>492.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>4.590</td>\n",
       "      <td>14.70</td>\n",
       "      <td>337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-55-8207-01</td>\n",
       "      <td>77.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>784.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>2.540</td>\n",
       "      <td>176.00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>923.0</td>\n",
       "      <td>2490.0</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-FF-A7CR-01</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>486.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.47</td>\n",
       "      <td>348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>897.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>DLBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-BK-A13C-11</td>\n",
       "      <td>80.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1.200</td>\n",
       "      <td>91.40</td>\n",
       "      <td>231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UCEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-EB-A6L9-06</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2.36</td>\n",
       "      <td>585.0</td>\n",
       "      <td>...</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>7010.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>SKCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id      1    10     100   1000   10000  10001  10002   10003  \\\n",
       "0  TCGA-LL-A73Z-01  202.0  28.5   329.0   84.5   492.0  448.0  4.590   14.70   \n",
       "1  TCGA-55-8207-01   77.5  22.5    74.5   13.1   784.0  333.0  2.540  176.00   \n",
       "2  TCGA-FF-A7CR-01  152.0   0.0  3020.0   26.6   486.0  497.0  0.000    8.47   \n",
       "3  TCGA-BK-A13C-11   80.5  40.0    70.6  284.0  2420.0  325.0  1.200   91.40   \n",
       "4  TCGA-EB-A6L9-06  319.0   0.0   422.0  184.0   423.0  392.0  0.945    2.36   \n",
       "\n",
       "   100037417  ...   9988    9989      999    9990    9991   9992    9993  \\\n",
       "0      337.0  ...  717.0  1800.0   6360.0   299.0  2310.0  10.60  3190.0   \n",
       "1      153.0  ...  923.0  2490.0  11300.0  1150.0  4030.0   9.08  2890.0   \n",
       "2      348.0  ...  897.0   861.0     39.7   464.0  3320.0   0.00  1330.0   \n",
       "3      231.0  ...  737.0  1410.0     10.9  1120.0  1990.0   5.24  3090.0   \n",
       "4      585.0  ...  328.0  1340.0   7010.0   450.0   563.0  10.90  3780.0   \n",
       "\n",
       "    9994    9997  cancer_type  \n",
       "0  337.0   892.0         BRCA  \n",
       "1  316.0   301.0         LUAD  \n",
       "2  606.0   558.0         DLBC  \n",
       "3  673.0   263.0         UCEC  \n",
       "4   37.3  1120.0         SKCM  \n",
       "\n",
       "[5 rows x 16150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tcga_df['cancer_type'] = merge_train\n",
    "train_tcga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "      <th>10002</th>\n",
       "      <th>10003</th>\n",
       "      <th>100037417</th>\n",
       "      <th>...</th>\n",
       "      <th>9988</th>\n",
       "      <th>9989</th>\n",
       "      <th>999</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9997</th>\n",
       "      <th>cancer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-CN-5365-01</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>73.9</td>\n",
       "      <td>757.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>10.50</td>\n",
       "      <td>414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>612.0</td>\n",
       "      <td>5780.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>HNSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-LP-A7HU-01</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.949</td>\n",
       "      <td>517.0</td>\n",
       "      <td>6.17</td>\n",
       "      <td>63.6</td>\n",
       "      <td>365.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>9.02</td>\n",
       "      <td>633.0</td>\n",
       "      <td>...</td>\n",
       "      <td>543.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>17.60</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>CESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-22-5491-11</td>\n",
       "      <td>87.6</td>\n",
       "      <td>3.760</td>\n",
       "      <td>88.3</td>\n",
       "      <td>14.40</td>\n",
       "      <td>642.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>59.90</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5030.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>LUSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-CS-6667-01</td>\n",
       "      <td>75.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55.6</td>\n",
       "      <td>2720.00</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>9.57</td>\n",
       "      <td>251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>23.70</td>\n",
       "      <td>7530.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-20-1684-01</td>\n",
       "      <td>63.1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>75.2</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>792.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.16</td>\n",
       "      <td>623.0</td>\n",
       "      <td>...</td>\n",
       "      <td>812.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>8410.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>OV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id     1     10     100     1000   10000  10001  10002  10003  \\\n",
       "0  TCGA-CN-5365-01  70.5  0.000  1310.0    18.70    73.9  757.0   1.82  10.50   \n",
       "1  TCGA-LP-A7HU-01  27.8  0.949   517.0     6.17    63.6  365.0   4.27   9.02   \n",
       "2  TCGA-22-5491-11  87.6  3.760    88.3    14.40   642.0  295.0   6.84  59.90   \n",
       "3  TCGA-CS-6667-01  75.8  0.000    55.6  2720.00  2170.0  281.0   3.90   9.57   \n",
       "4  TCGA-20-1684-01  63.1  0.703    75.2  4500.00   792.0  433.0   1.64   4.16   \n",
       "\n",
       "   100037417  ...    9988    9989      999    9990    9991   9992    9993  \\\n",
       "0      414.0  ...   612.0  5780.0  10400.0   879.0  3830.0   4.10  4220.0   \n",
       "1      633.0  ...   543.0  1360.0   4960.0   510.0  2220.0  17.60  2410.0   \n",
       "2      159.0  ...   479.0  2190.0   4480.0   870.0  2120.0   5.13  5030.0   \n",
       "3      251.0  ...  1550.0  1370.0     12.8  1430.0   601.0  23.70  7530.0   \n",
       "4      623.0  ...   812.0  1070.0   8410.0   505.0  1170.0  14.80  1910.0   \n",
       "\n",
       "    9994    9997  cancer_type  \n",
       "0  308.0  1300.0         HNSC  \n",
       "1  233.0   993.0         CESC  \n",
       "2  285.0   530.0         LUSC  \n",
       "3  473.0   258.0          LGG  \n",
       "4  281.0   221.0           OV  \n",
       "\n",
       "[5 rows x 16150 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tcga_df['cancer_type'] = merge_test\n",
    "test_tcga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, var_layer, mean_layer, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        self.var_layer = var_layer\n",
    "        self.mean_layer = mean_layer\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.var_layer - K.square(self.mean_layer) - \n",
    "                                K.exp(self.var_layer), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tybalt():\n",
    "    \"\"\"\n",
    "    Facilitates the training and output of tybalt model trained on TCGA RNAseq gene expression data\n",
    "    \"\"\"\n",
    "    def __init__(self, original_dim, hidden_dim, latent_dim,\n",
    "                 batch_size, epochs, learning_rate, kappa, beta):\n",
    "        self.original_dim = original_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kappa = kappa\n",
    "        self.beta = beta\n",
    "\n",
    "    def build_encoder_layer(self):\n",
    "        # Input place holder for RNAseq data with specific input size\n",
    "        self.rnaseq_input = Input(shape=(self.original_dim, ))\n",
    "\n",
    "        # Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "        # Each layer is initialized with glorot uniform weights and each step (dense connections, batch norm,\n",
    "        # and relu activation) are funneled separately\n",
    "        # Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "        hidden_dense_linear = Dense(self.hidden_dim, kernel_initializer='glorot_uniform')(self.rnaseq_input)\n",
    "        hidden_dense_batchnorm = BatchNormalization()(hidden_dense_linear)\n",
    "        hidden_encoded = Activation('relu')(hidden_dense_batchnorm)\n",
    "\n",
    "        z_mean_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "        self.z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "        z_log_var_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "        self.z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "        # return the encoded and randomly sampled z vector\n",
    "        # Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "        self.z = Lambda(sampling, output_shape=(self.latent_dim, ))([self.z_mean_encoded, self.z_log_var_encoded])\n",
    "    \n",
    "    def build_decoder_layer(self):\n",
    "        # The decoding layer is much simpler with a single layer glorot uniform initialized and sigmoid activation\n",
    "        self.decoder_model = Sequential()\n",
    "        self.decoder_model.add(Dense(self.hidden_dim, activation='relu', input_dim=self.latent_dim))\n",
    "        self.decoder_model.add(Dense(self.original_dim, activation='sigmoid'))\n",
    "        self.rnaseq_reconstruct = self.decoder_model(self.z)\n",
    "        \n",
    "    def compile_vae(self):\n",
    "        adam = optimizers.Adam(lr=self.learning_rate)\n",
    "        vae_layer = CustomVariationalLayer(self.z_log_var_encoded,\n",
    "                                           self.z_mean_encoded)([self.rnaseq_input, self.rnaseq_reconstruct])\n",
    "        self.vae = Model(self.rnaseq_input, vae_layer)\n",
    "        self.vae.compile(optimizer=adam, loss=None, loss_weights=[self.beta])\n",
    "        \n",
    "    def get_summary(self):\n",
    "        self.vae.summary()\n",
    "  \n",
    "    def visualize_architecture(self, output_file):\n",
    "        # Visualize the connections of the custom VAE model\n",
    "        plot_model(self.vae, to_file=output_file)\n",
    "        SVG(model_to_dot(self.vae).create(prog='dot', format='svg'))\n",
    "        \n",
    "    def train_vae(self):\n",
    "        self.hist = self.vae.fit(np.array(rnaseq_train_df),\n",
    "               shuffle=True,\n",
    "               epochs=self.epochs,\n",
    "               batch_size=self.batch_size,\n",
    "               validation_data=(np.array(rnaseq_test_df), np.array(rnaseq_test_df)),\n",
    "               callbacks=[WarmUpCallback(self.beta, self.kappa)])\n",
    "    \n",
    "    def visualize_training(self, output_file):\n",
    "        # Visualize training performance\n",
    "        history_df = pd.DataFrame(self.hist.history)\n",
    "        ax = history_df.plot()\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('VAE Loss')\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(output_file)\n",
    "        \n",
    "    def compress(self, df):\n",
    "        # Model to compress input\n",
    "        self.encoder = Model(self.rnaseq_input, self.z_mean_encoded)\n",
    "        \n",
    "        # Encode rnaseq into the hidden/latent representation - and save output\n",
    "        encoded_df = self.encoder.predict_on_batch(df)\n",
    "        encoded_df = pd.DataFrame(encoded_df, columns=range(1, self.latent_dim + 1),\n",
    "                                  index=rnaseq_df.index)\n",
    "        return encoded_df\n",
    "    \n",
    "    def get_decoder_weights(self):\n",
    "        # build a generator that can sample from the learned distribution\n",
    "        decoder_input = Input(shape=(self.latent_dim, ))  # can generate from any sampled z vector\n",
    "        _x_decoded_mean = self.decoder_model(decoder_input)\n",
    "        self.decoder = Model(decoder_input, _x_decoded_mean)\n",
    "        weights = []\n",
    "        for layer in self.decoder.layers:\n",
    "            weights.append(layer.get_weights())\n",
    "        return(weights)\n",
    "    \n",
    "    def predict(self, df):\n",
    "        return self.decoder.predict(np.array(df))\n",
    "    \n",
    "    def save_models(self, encoder_file, decoder_file):\n",
    "        self.encoder.save(encoder_file)\n",
    "        self.decoder.save(decoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common hyper parameters\n",
    "rnaseq_train_df = train_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "rnaseq_test_df = test_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "\n",
    "original_dim = rnaseq_train_df.shape[1]\n",
    "latent_dim = 100\n",
    "beta = K.variable(0)\n",
    "epsilon_std = 1.0\n",
    "\n",
    "# Model A (100 hidden layer size)\n",
    "model_a_latent_dim = 100\n",
    "model_a_batch_size = 100\n",
    "model_a_epochs = 100\n",
    "model_a_learning_rate = 0.001\n",
    "model_a_kappa = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Tybalt(original_dim=original_dim,\n",
    "                 hidden_dim=model_a_latent_dim,\n",
    "                 latent_dim=latent_dim,\n",
    "                 batch_size=model_a_batch_size,\n",
    "                 epochs=model_a_epochs,\n",
    "                 learning_rate=model_a_learning_rate,\n",
    "                 kappa=model_a_kappa,\n",
    "                 beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 16148)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 100)           1614900     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 100)           400         dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 100)           0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 100)           10100       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 100)           10100       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 100)           400         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 100)           400         dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 100)           0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 100)           0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 100)           0           activation_5[0][0]               \n",
      "                                                                   activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 16148)         1641048     lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_2 (Cust [(None, 16148), (None 0           input_3[0][0]                    \n",
      "                                                                   sequential_2[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 3,277,348\n",
      "Trainable params: 3,276,748\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_2\" during training.\n"
     ]
    }
   ],
   "source": [
    "# Compile Model A\n",
    "model_a.build_encoder_layer()\n",
    "model_a.build_decoder_layer()\n",
    "model_a.compile_vae()\n",
    "model_a.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 19s - loss: -184127256.0116 - val_loss: -288975562.0687\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 19s - loss: -313611034.2262 - val_loss: -311879839.8843\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 19s - loss: -314340222.2704 - val_loss: -314460064.6944\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 19s - loss: -314359820.1198 - val_loss: -314736265.3165\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 19s - loss: -314521814.8700 - val_loss: -314625035.9783\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 19s - loss: -314581886.8877 - val_loss: -314801550.2929\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 19s - loss: -314557361.4113 - val_loss: -314848673.4467\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 19s - loss: -314586555.3257 - val_loss: -314850717.9168\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 19s - loss: -314652372.0217 - val_loss: -314852391.5226\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 19s - loss: -314639619.7934 - val_loss: -314771130.0398\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 19s - loss: -314628579.3755 - val_loss: -314847938.3725\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 19s - loss: -314646680.3295 - val_loss: -314852298.9367\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 20s - loss: -314669744.0804 - val_loss: -314852449.2152\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 20s - loss: -314661038.2672 - val_loss: -314686488.8246\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 20s - loss: -314660316.5280 - val_loss: -314819575.6094\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 20s - loss: -314659919.9968 - val_loss: -314852509.8011\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 20s - loss: -314641613.3028 - val_loss: -314846237.2803\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 20s - loss: -314672967.0275 - val_loss: -314848488.2749\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 20s - loss: -314682437.4844 - val_loss: -314852515.7613\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 20s - loss: -314685804.0040 - val_loss: -314757016.1302\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687507.4430 - val_loss: -314852521.7215\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 20s - loss: -314668159.8328 - val_loss: -314852515.7613\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 20s - loss: -314676035.8835 - val_loss: -314845473.6203\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 20s - loss: -314677425.5013 - val_loss: -314719930.0398\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687564.6663 - val_loss: -314852515.9349\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 20s - loss: -314671898.7728 - val_loss: -314852449.3888\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 20s - loss: -314680434.1957 - val_loss: -314852521.5479\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 20s - loss: -314675127.4229 - val_loss: -314852495.6817\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 20s - loss: -314681012.8768 - val_loss: -314852495.6817\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687472.6140 - val_loss: -314852518.8282\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685851.1007 - val_loss: -314852518.6546\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687198.1997 - val_loss: -314852524.6148\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: -314680245.7255 - val_loss: -314852451.9349\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683770.3934 - val_loss: -314852165.6709\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 19s - loss: -314669952.0257 - val_loss: -314852504.3617\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687672.1816 - val_loss: -314852466.7486\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687584.1415 - val_loss: -314852417.5624\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687696.6397 - val_loss: -314852521.7215\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687737.8726 - val_loss: -314852530.4014\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687722.9881 - val_loss: -314849882.8499\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687742.5598 - val_loss: -314852518.6546\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683870.4762 - val_loss: -314852521.7215\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687732.7740 - val_loss: -314852524.7884\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 20s - loss: -314685847.7380 - val_loss: -314852452.1085\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687738.3420 - val_loss: -314851106.8933\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 20s - loss: -314684307.9188 - val_loss: -314843737.4611\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687734.4264 - val_loss: -314852524.6148\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 20s - loss: -314675013.1822 - val_loss: -314852458.0687\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 21s - loss: -314687702.2335 - val_loss: -314852513.0416\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687622.5453 - val_loss: -314852524.6148\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685841.7778 - val_loss: -314852524.6148\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 19s - loss: -314677768.0177 - val_loss: -314852533.2948791.59\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687745.4595 - val_loss: -314852527.5081\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687718.7318 - val_loss: -314851306.5316\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.3464 - val_loss: -314852521.7215\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687743.7107 - val_loss: -314852533.2948\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687543.6737 - val_loss: -314852527.3345\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687633.3663 - val_loss: -314852521.7215\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.8286 - val_loss: -314852530.4014\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.6172 - val_loss: -314852524.6148\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.2110 - val_loss: -314852524.6148\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.4073 - val_loss: -314852527.5081\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.7159 - val_loss: -314852527.8553\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.5714 - val_loss: -314852527.5081\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687739.8079 - val_loss: -314852524.6148\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687745.7553 - val_loss: -314852527.5081\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685482.7760 - val_loss: -314852507.4286\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 19s - loss: -314644564.1246 - val_loss: -314825807.7975\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687729.3599 - val_loss: -314851856.2604\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687737.0046 - val_loss: -314852524.9620\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687734.6192 - val_loss: -314852524.9620\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 19s - loss: -314687730.7422 - val_loss: -314852524.7884\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687690.7631 - val_loss: -314852515.9349\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683862.7864 - val_loss: -314852437.8156\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 20s - loss: -314683551.2927 - val_loss: -314654526.7848\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 19s - loss: -314674888.3134 - val_loss: -314852478.1483\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685635.8513 - val_loss: -314852530.0542\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687746.7840 - val_loss: -314852524.6148\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687747.2727 - val_loss: -314852527.5081\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.5787 - val_loss: -314852524.6148\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687747.4527 - val_loss: -314840502.9150\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687739.3578 - val_loss: -314852541.9747\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687339.4061 - val_loss: -314852507.2550\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687689.2779 - val_loss: -314852530.4014\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686179.3369 - val_loss: -314852530.4014\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 19s - loss: -314678350.9809 - val_loss: -314813320.4485\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.9259 - val_loss: -314852521.7215\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685654.7607 - val_loss: -314852524.7884\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.6357 - val_loss: -314852530.4014\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.2329 - val_loss: -314852533.4684\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.6739 - val_loss: -314852539.0814\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686916.0635 - val_loss: -314852530.4014\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.4000 - val_loss: -314852539.2550\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686987.0139 - val_loss: -314852527.5081\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687752.2877 - val_loss: -314852530.7486\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.6829 - val_loss: -314852536.3617\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687755.3289 - val_loss: -314852539.2550\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.6452 - val_loss: -314852536.5353\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.8989 - val_loss: -314852524.9620\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687754.6345 - val_loss: -314852542.3219\n"
     ]
    }
   ],
   "source": [
    "model_a.train_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq_df = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "\n",
    "model_a_compression = model_a.compress(rnaseq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/learning.pdf'\n",
    "compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/compress.tsv'\n",
    "encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/encoder_twohidden100_vae.hdf5'\n",
    "decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/decoder_twohidden100_vae.hdf5'\n",
    "weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/enc_dec_weights.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_a.visualize_training(learning_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_weights = model_a.get_decoder_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_compression.to_csv(compress_path, sep='\\t', compression='gzip')\n",
    "model_a.save_models(encoder_path, decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(weights, weight_file):\n",
    "    # Multiply hidden layers together to obtain a single representation of gene weights\n",
    "    intermediate_weight_df = pd.DataFrame(weights[1][0])\n",
    "    hidden_weight_df = pd.DataFrame(weights[1][2])\n",
    "    abstracted_weight_df = intermediate_weight_df.dot(hidden_weight_df)\n",
    "\n",
    "    abstracted_weight_df.index = range(1, 101)\n",
    "    abstracted_weight_df.columns = rnaseq_df.columns\n",
    "    abstracted_weight_df.to_csv(weight_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weights(model_a_weights, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11060, 100)\n",
      "(11060, 16148)\n"
     ]
    }
   ],
   "source": [
    "compress_data = model_a_compression\n",
    "full_data = rnaseq_df\n",
    "\n",
    "print(compress_data.shape)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006710269524288125\n",
      "0.07239622342418503\n"
     ]
    }
   ],
   "source": [
    "reconstructed_data = pd.DataFrame(model_a.predict(compress_data))\n",
    "\n",
    "#r = pearsonr([1,2,3], [4,3,2])\n",
    "\n",
    "\n",
    "r = [pearsonr(reconstructed_data.iloc[x, :], full_data.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "\n",
    "s = [spearmanr(reconstructed_data.iloc[x, :], full_data.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "\n",
    "\n",
    "print(np.mean(r))\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
